[
["index.html", "Getting started with R Chapter 1 Course info 1.1 Course materials and structure 1.2 Structure 1.3 Getting help", " Getting started with R Matthew Upson 2017-04-14 Chapter 1 Course info This course was originally delivered in 2012 for a class of researchers and research students at Cranfield University, most with little or no experience of R. As I have continued to teach R in various capacities ever since, I have updated this course to provide more up-to-date material for those coming to R for teh first time in 2016. The aim of this course remains the same as the original: This course is designed to give you a brief introduction to the statistical programming environment R. This is not a course on which statistics to use and why, it is primarily concerned with getting you started with the R language, and as such assumes a basic levels of statistical knowledge. In its previous incarnation, this book relied on examples from Mick Crawley’s seminal text’The R Book’. This course relies less on that book, and although a little dated now, it remains ane excellent resource, especially when using R for generalised linear modelling. 1.1 Course materials and structure All the course materials are available here. In addition you will need to download data from the internet for certain exercises, but this will be explained to you in the appropriate section. 1.2 Structure The course is divided into four main sections: Getting started Moving data around Visualising your data Basic data analysis Follow the links on teh left hand side to get around. As you go along, You will be able to copy and paste the code from these notes directly into the R console., but do try to understand what it is you are doing! In addition there are a number of exercises throughout. These are indicated by a box: Exercise This is an exercise 1.3 Getting help Getting help with R is very easy - there is a thriving online community of R users who, so the chances are that if you have a problem, someone else will have posted a solution online before you. 1.3.1 Within R It is possible to get help in R itself. If you are interested in a function, you can simply type the name of that function into the console preceded by a question mark. This will bring up the relevant help file - although they are not always that easy to decipher! 1.3.2 Books and guides There are also many online guides available - googling ‘R guide’ will reveal many, but three are listed below: http://www.rstudio.com/ide/docs/help_with_r http://cran.r-project.org/doc/contrib/Owen-TheRGuide.pdf https://sites.google.com/site/undergraduateguidetor/ I point the reader particularly in the direction of: Advanced R R for Data Science 1.3.3 Forums Forums are a great place for R help - again try googling this, although arguably the best is: http://stackoverflow.com/. Make sure you read the rules of the forum carefully, as contributors often don’t take kindly to poorly stated questions! That said, if you don’t get an answer on Stack Overflow, you have found a very tricky problem indeed. "],
["R-environment.html", "Chapter 2 The R environment 2.1 The R console 2.2 The scripting window 2.3 The plotting window", " Chapter 2 The R environment 2.1 The R console The first thing you will notice when you open R, is that there are not a great deal of buttons! In fact, you will be confronted by the window below or the ‘R Console’. It is in this window that we can type commands, and in this window that we will get results returned While we will get to the more complicated commands that you can pass to Rvia the console, it can also function as a high level calculator. Throughout this course, when you see text displayed like this: 1 + 2 + 3 ## [1] 6 This is essentially a command that has been run in the console, with lines preceded by ## the response returned in the console. As you go along, you should replicate these commands by copying and pasting the commands into your console window. Note that there are all the usual functions you would expect from a good scientific calculator…and more. 2.2 The scripting window The basic R installation allows you to write ‘scripts’ saved as .R files, in which you can save your code. You can open a new scripting window by going to the drop-down menu File&gt;New script. Once here, you can write your codes, and send it to the R console by pressing CTRL + r line by line, or CTRL + a to select all and CTRL + r to run all the selected code. 2.3 The plotting window When you create a plot, a new window will open, in which your plot will appear. Every time you create a new plot, your old plot will be replaced by the new one. You can prevent this from happening, by running the command windows() (windows only!) before creating a plot, which will create a new plotting window, allowing you to keep several plots at any one time. "],
["R-style.html", "Chapter 3 R coding style", " Chapter 3 R coding style Believe it or not, quite a lot of discussion (online discussion that is) goes into the question of what your R code should look like when you write it, i.e. where you should put spaces, how you should name files, etc. For example 1: # Good if (debug) plot(x, y) # Bad if(debug) plot (x, y) In the above example, it makes no difference at all how the code is interpreted by R, but it can make the difference between code that is easy to read, and code that isn’t. This is especially important if you are sharing your code with collaborators, as there is nothing worse than having to re-arrange someone else’s code before you can even read it! Throughout this document I have adhered (loosely in places) to Hadley Wickham’s style guide, which is based on the Google style guide. If you want to explicitly know what this means - follow the link above and have a read - this is probably a good idea once you have had some practice with the language. By all means, if you prefer, use a different style, it really doesn’t matter so long as your code is clear and easy to read. Some important rules to follow, whichever style you decide to follow however are: Be consistent: use the same style throughout all your scripts Make file and object names meaningful: don’t fall into the lazy practice of calling objects a or b, or other unhelpful names. Comment your code liberally: explain why you are doing what you are doing - it makes it so much easier when either you go back to code you wrote months earlier, or when sharing your code with other collaborators. Other style guides do exist, for example the google style guide http://google-styleguide.googlecode.com/svn/trunk/Rguide.xml or the 4D Pie charts guide (http://4dpiecharts.com/r-code-style-guide/). Hadley Wickam style guide https://github.com/hadley/devtools/wiki/Style↩ "],
["installing-r-packages.html", "Chapter 4 Installing R Packages", " Chapter 4 Installing R Packages One of the strengths of R is that there are literally thousands of packages available for you to extend to core capabilities if the R statistical environment. You may one day even with to write your own packages. Downloading and installing packages is a very simple procedure in R and can be done with a single line of code – You will probably do this a lot! Int his instance, we specify the repository from which we will download the package - if you omitted repos=&quot;&quot; then you would be asked to select a repository from a list. Rstudio’s mirror is hosted by amazon, and hence, is pretty fast - so we’ll use that one. install.packages(&#39;agricolae&#39;, repos=&quot;http://cran.rstudio.com/&quot;) ## Installing package into &#39;/home/travis/R/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;gtools&#39;, &#39;gdata&#39;, &#39;combinat&#39;, &#39;sp&#39;, &#39;LearnBayes&#39;, &#39;deldir&#39;, &#39;coda&#39;, &#39;gmodels&#39;, &#39;expm&#39;, &#39;klaR&#39;, &#39;spdep&#39;, &#39;AlgDesign&#39; R will then download the package and install it in the relevant directory. In order to use the package you need to call the package using library(agricolae). This may or may not generate a message or warning. library(agricolae) If you wanto to suppress warnings (for instance if you wish to call a package from within a function) you can also use require(agricolae) (there are subtle difference between library() and require() – see a good explanation here). Note that you will need to call the package with library() every time you run a new instance of R. Running the install.packages() command will also update a package to the latest available version if you already have that package. "],
["getting-data-into-R.html", "Chapter 5 Getting data into R 5.1 Small variables 5.2 Importing tables", " Chapter 5 Getting data into R Probably the first question you are likely to ask when approaching R for the first time is ‘how do I get my data into R’? R is able to read directly from excel spread sheets using a number of packages, however they usually take some tweaking. In this tutorial we will restrict ourselves to importing data from ‘comma separated values’ (.csv) files and ‘tab delimited’ text files (.txt). You can create files in this format using the ‘Save As’ menu in Excel, or whichever spread sheet software you are using. 5.1 Small variables Sometimes you will need to insert data into R which is small and is not stored in an external file. There are two easy wasy to do this. Note that in the following (and all subsequent code chunks) anything preceded with a # is ignored by R and referred to as a ‘comment’. It is a good idea to get into the habit of commenting every few lines of code, and explain why - not necessarily how (as this will be self evident) you have written a certain line of code. It makes reading code much easier, especially if you didn’t write it. In the following example we use the c() or concatenate function. This works exactly the same way in R as the CONCATENATE() function in Excel, which you may be familiar with. In the example that follows, we call the function c() and specify a number of ‘arguments’ which follow - in this case a string of numbers that we want to combine. Get used to the idea of calling functions like this with a number of arguments following - we will do this a lot! # Create an object called short_variable, and assign a series of numbers to it. # We use &#39;&lt;-&#39; to create the object. This is called &#39;gets&#39;. short_variable &lt;- c(1,5,6,7,9,2,10) # To see what is contained within an object, simply input the name of the object. short_variable ## [1] 1 5 6 7 9 2 10 # Note that this the equivalent in R of writing print(short_variable). # This is not particularly important in this course, but it becomes important # as you begin to write your own functions. print(short_variable) ## [1] 1 5 6 7 9 2 10 A more convenient way of entering a series of numbers is to use the scan() function. You must still assign a name to the object you are creating as before, but scan() Will allow you to enter the data more easily. Try that now. 5.2 Importing tables Obviously you won’t want to manually input all your data, it is much easier to import from a file which you have prepared in a spread sheet. As mentioned, in this course we will work exclusively with the simple formats ‘.csv’ and .txt. When importing data from files, there are a few rules that must be adhered to, otherwise R will throw up an error. Data must be complete. Any missing values should be replaced with NA. There must be no spaces in text (e.g. column titles), you should either use underscores, e.g.: my_variable, or conflate words using capitals to sperate, e.g.: myVariable. Data should be arranged in ‘long’ format and be ‘tidy’. This is required for many types of analysis in R - a good paper on this can be found here - more on this later. Let’s assume we’ve done that already: To import from a ‘.txt’ file we used the read.table() function again you must assign the function a name first. In this case we will import a data file referred to in ‘The R book’. Notice that we are able to import it directly from the internet, but the location could just as easily be a local folder: “C://data/”. rats &lt;- read.table( &quot;http://www.bio.ic.ac.uk/research/mjcraw/therbook/data/rats.txt&quot;, header = T ) Noew we can call the data to examine it. Note this data is dealt with on p475 of ‘The R Book’ rats ## Glycogen Treatment Rat Liver ## 1 131 1 1 1 ## 2 130 1 1 1 ## 3 131 1 1 2 ## 4 125 1 1 2 ## 5 136 1 1 3 ## 6 142 1 1 3 ## 7 150 1 2 1 ## 8 148 1 2 1 ## 9 140 1 2 2 ## 10 143 1 2 2 ## 11 160 1 2 3 ## 12 150 1 2 3 ## 13 157 2 1 1 ## 14 145 2 1 1 ## 15 154 2 1 2 ## 16 142 2 1 2 ## 17 147 2 1 3 ## 18 153 2 1 3 ## 19 151 2 2 1 ## 20 155 2 2 1 ## 21 147 2 2 2 ## 22 147 2 2 2 ## 23 162 2 2 3 ## 24 152 2 2 3 ## 25 134 3 1 1 ## 26 125 3 1 1 ## 27 138 3 1 2 ## 28 138 3 1 2 ## 29 135 3 1 3 ## 30 136 3 1 3 ## 31 138 3 2 1 ## 32 140 3 2 1 ## 33 139 3 2 2 ## 34 138 3 2 2 ## 35 134 3 2 3 ## 36 127 3 2 3 This isn’t a particularly big table so we can view the whole thing at once, but if it was longer we might want to summarise the data or look at smaller chunks fo it. We can look at the first 6 rows with head(): head(rats) ## Glycogen Treatment Rat Liver ## 1 131 1 1 1 ## 2 130 1 1 1 ## 3 131 1 1 2 ## 4 125 1 1 2 ## 5 136 1 1 3 ## 6 142 1 1 3 Or the last six rows with tail(): tail(rats) ## Glycogen Treatment Rat Liver ## 31 138 3 2 1 ## 32 140 3 2 1 ## 33 139 3 2 2 ## 34 138 3 2 2 ## 35 134 3 2 3 ## 36 127 3 2 3 We can select individual columns or rows with square brackets. # rats[1,1] will give you the value on the first row of the first column: rats[1,1] ## [1] 131 # The first number denotes row, the second column. So to see the whole first row, we do: rats[1,] ## Glycogen Treatment Rat Liver ## 1 131 1 1 1 # We can also specify a series by using a colon: rats[1:10,] ## Glycogen Treatment Rat Liver ## 1 131 1 1 1 ## 2 130 1 1 1 ## 3 131 1 1 2 ## 4 125 1 1 2 ## 5 136 1 1 3 ## 6 142 1 1 3 ## 7 150 1 2 1 ## 8 148 1 2 1 ## 9 140 1 2 2 ## 10 143 1 2 2 # If we wanted every third row, we could use the seq() function: rats[seq(3,36,3),] ## Glycogen Treatment Rat Liver ## 3 131 1 1 2 ## 6 142 1 1 3 ## 9 140 1 2 2 ## 12 150 1 2 3 ## 15 154 2 1 2 ## 18 153 2 1 3 ## 21 147 2 2 2 ## 24 152 2 2 3 ## 27 138 3 1 2 ## 30 136 3 1 3 ## 33 139 3 2 2 ## 36 127 3 2 3 # In this case the three arguments in the seq function mean: start at value 3, end at value 36, and jump 3 rows at a time. # We can also compute some summary statistics from the data: summary(rats) ## Glycogen Treatment Rat Liver ## Min. :125.0 Min. :1 Min. :1.0 Min. :1 ## 1st Qu.:135.8 1st Qu.:1 1st Qu.:1.0 1st Qu.:1 ## Median :141.0 Median :2 Median :1.5 Median :2 ## Mean :142.2 Mean :2 Mean :1.5 Mean :2 ## 3rd Qu.:150.0 3rd Qu.:3 3rd Qu.:2.0 3rd Qu.:3 ## Max. :162.0 Max. :3 Max. :2.0 Max. :3 # Or look at the structure of the object str(rats) ## &#39;data.frame&#39;: 36 obs. of 4 variables: ## $ Glycogen : int 131 130 131 125 136 142 150 148 140 143 ... ## $ Treatment: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Rat : int 1 1 1 1 1 1 2 2 2 2 ... ## $ Liver : int 1 1 2 2 3 3 1 1 2 2 ... str() is useful, because it lets us know how R is seeing the parts of this table. int for instance means integer. If we were wanting to conduct an ANOVA on the rats data, we would need to tell R that Treatment, Rat and, Liver are categorical values, not continuous, otherwise we would be doing the wrong analysis. Note that R will always assume integers to be continuous, unless we explicitly tell it otherwise by labelling it as a factor. # To solve this, either use characters - A, B, C instead of 1, 2, 3 for factors, or convert them manually: rats$Treatment &lt;- factor(rats$Treatment) # By using the factor command, we in effect convert a continuous variable into a categorical one: str(rats) ## &#39;data.frame&#39;: 36 obs. of 4 variables: ## $ Glycogen : int 131 130 131 125 136 142 150 148 140 143 ... ## $ Treatment: Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Rat : int 1 1 1 1 1 1 2 2 2 2 ... ## $ Liver : int 1 1 2 2 3 3 1 1 2 2 ... Now convert Rat and Liver into categorical variables in the same way - we will need this data later. There is a dedicated function revalue() to convert numerical factor levels to character based levels in the library plyr. This can save you the hassle of using factor() each time you open a dataset (although you could of course do this in your spreadsheet). # Install the package plyr - if you don&#39;t have it already - note you can check this on the right hand &#39;packages&#39; tab of RStudio. But, it doesn&#39;t hurt to run the command again, even if it is installed! install.packages(&#39;plyr&#39;,repos=&quot;http://cran.rstudio.com/&quot;) ## Installing package into &#39;/home/travis/R/Library&#39; ## (as &#39;lib&#39; is unspecified) # Load the package: library(plyr) rats$Treatment1 &lt;- revalue(rats$Treatment, c(&quot;1&quot; = &quot;A&quot;, &quot;2&quot; = &quot;B&quot;, &quot;3&quot; = &quot;C&quot;)) rats$Treatment ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 ## [36] 3 ## Levels: 1 2 3 rats$Treatment1 ## [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C ## [36] C ## Levels: A B C Note that in these two examples we refer to the individual columns of the table with a $. R studio is great for this. Type rats$ in the console and the press the tab button. RStudio will then automatically complete the variable name, or give you the options available. Try it. We could also have referred to the columns by number: rats[ ,1]. Another option which gives you a much more familiar spread sheet like view is fix(rats) - try this too. If you have followed the above instructions, you should have something that looks like this: str(rats) ## &#39;data.frame&#39;: 36 obs. of 5 variables: ## $ Glycogen : int 131 130 131 125 136 142 150 148 140 143 ... ## $ Treatment : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Rat : Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 1 1 1 1 2 2 2 2 ... ## $ Liver : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 2 2 3 3 1 1 2 2 ... ## $ Treatment1: Factor w/ 3 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;: 1 1 1 1 1 1 1 1 1 1 ... rats ## Glycogen Treatment Rat Liver Treatment1 ## 1 131 1 1 1 A ## 2 130 1 1 1 A ## 3 131 1 1 2 A ## 4 125 1 1 2 A ## 5 136 1 1 3 A ## 6 142 1 1 3 A ## 7 150 1 2 1 A ## 8 148 1 2 1 A ## 9 140 1 2 2 A ## 10 143 1 2 2 A ## 11 160 1 2 3 A ## 12 150 1 2 3 A ## 13 157 2 1 1 B ## 14 145 2 1 1 B ## 15 154 2 1 2 B ## 16 142 2 1 2 B ## 17 147 2 1 3 B ## 18 153 2 1 3 B ## 19 151 2 2 1 B ## 20 155 2 2 1 B ## 21 147 2 2 2 B ## 22 147 2 2 2 B ## 23 162 2 2 3 B ## 24 152 2 2 3 B ## 25 134 3 1 1 C ## 26 125 3 1 1 C ## 27 138 3 1 2 C ## 28 138 3 1 2 C ## 29 135 3 1 3 C ## 30 136 3 1 3 C ## 31 138 3 2 1 C ## 32 140 3 2 1 C ## 33 139 3 2 2 C ## 34 138 3 2 2 C ## 35 134 3 2 3 C ## 36 127 3 2 3 C Note that a longer discussion of getting data from excel files is available here: http://www.r-bloggers.com/read-excel-files-from-r/. "],
["selecting-data.html", "Chapter 6 Selecting data", " Chapter 6 Selecting data In the previous section, we dealt a little with the question of selecting parts of your data from an imported table. We will expand on that introduction here by introducing some additional commands. For the next example, we will use the R mtcars dataset: ‘The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973-74 models)’ (see ?mtcars). First we call and examine the data. mtcars ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... So it’s a reasonably complex (if short) dataset, with a number of variables that we might be interested in. Suppose we wanted to select all the cars which have 5 forward gears (the gear variable): there are a number of ways of doing this. We can start by selecting a ‘logical’ subset. mtcars[mtcars$gear == 5,] ## mpg cyl disp hp drat wt qsec vs am gear carb ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.7 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.5 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.5 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.6 0 1 5 8 In this example we select only the rows which match out conditions mtcars$gear == 5, and all the columns. We can specify a particular column numerically if required: mtcars[mtcars$gear == 5,1:2] ## mpg cyl ## Porsche 914-2 26.0 4 ## Lotus Europa 30.4 4 ## Ford Pantera L 15.8 8 ## Ferrari Dino 19.7 6 ## Maserati Bora 15.0 8 We can also use the column title to select columns. mtcars[mtcars$gear == 5,c(&quot;mpg&quot;,&quot;gear&quot;)] ## mpg gear ## Porsche 914-2 26.0 5 ## Lotus Europa 30.4 5 ## Ford Pantera L 15.8 5 ## Ferrari Dino 19.7 5 ## Maserati Bora 15.0 5 And we can use more than one criteria if required… mtcars[mtcars$mpg &gt; 30 &amp; mtcars$mpg &lt; 40,c(&quot;mpg&quot;)] ## [1] 32.4 30.4 33.9 30.4 Notice that in this example, because we specify just one column, the code outputs a vector of numbers, not a dataframe (more on this later) with row and column names. Also note that in all these examples were, rather tiresomely, have to specify mtcars$gear, but there is a simpler way: subset( x = mtcars, subset = mpg &gt; 30 &amp; mpg &lt; 40, select = mpg ) ## mpg ## Fiat 128 32.4 ## Honda Civic 30.4 ## Toyota Corolla 33.9 ## Lotus Europa 30.4 subset() simplifies the syntax for logical subsets, and note that even when you select just one column, it will output column and row names. If you want to select more than one column you will need to use c() to concatenate a vector names: subset( x = mtcars, subset = mpg &gt; 30 &amp; mpg &lt; 40, select = c(mpg,gear,cyl) ) ## mpg gear cyl ## Fiat 128 32.4 4 4 ## Honda Civic 30.4 4 4 ## Toyota Corolla 33.9 4 4 ## Lotus Europa 30.4 5 4 If you omit the select argument, you will end up with all the columns: subset( x = mtcars, subset = mpg &gt; 30 &amp; mpg &lt; 40 ) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 And note that you can also use select() to omit columns: subset( x = mtcars, subset = mpg &gt; 30 &amp; mpg &lt; 40, select = -c(mpg,disp,hp) ) ## cyl drat wt qsec vs am gear carb ## Fiat 128 4 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 4 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 4 4.22 1.835 19.90 1 1 4 1 ## Lotus Europa 4 3.77 1.513 16.90 1 1 5 2 Or using : to select or deselect a range of columns: subset( x = mtcars, subset = mpg &gt; 30 &amp; mpg &lt; 40, select = -c(mpg:wt) ) ## qsec vs am gear carb ## Fiat 128 19.47 1 1 4 1 ## Honda Civic 18.52 1 1 4 2 ## Toyota Corolla 19.90 1 1 4 1 ## Lotus Europa 16.90 1 1 5 2 subset( x = mtcars, subset = mpg &gt; 30 &amp; mpg &lt; 40, select = c(mpg:wt) ) ## mpg cyl disp hp drat wt ## Fiat 128 32.4 4 78.7 66 4.08 2.200 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 6.0.1 Exercise Using the data you imported in the last exercise on the previous page, reproduce the same answers, this time using the subset() methods covered on this page. i.e.: …create a summary of the last three columns,and create a new object called maximae including only rows 144, 542, 965, 1371 and 1769. "],
["scatter-plots.html", "Chapter 7 Scatter-plots", " Chapter 7 Scatter-plots The basic plotting functions are very easy, but we first need some data to work with. For this example we are going to use one of the inbuilt datasets. There are a number of datasets which come readily loaded with the datasets package. In this example we are using the trees dataset, which contains ‘measurements of the girth, height and volume of timber in 31 felled black cherry trees’ (See ?trees for more information) First, we will look at the data. trees ## Girth Height Volume ## 1 8.3 70 10.3 ## 2 8.6 65 10.3 ## 3 8.8 63 10.2 ## 4 10.5 72 16.4 ## 5 10.7 81 18.8 ## 6 10.8 83 19.7 ## 7 11.0 66 15.6 ## 8 11.0 75 18.2 ## 9 11.1 80 22.6 ## 10 11.2 75 19.9 ## 11 11.3 79 24.2 ## 12 11.4 76 21.0 ## 13 11.4 76 21.4 ## 14 11.7 69 21.3 ## 15 12.0 75 19.1 ## 16 12.9 74 22.2 ## 17 12.9 85 33.8 ## 18 13.3 86 27.4 ## 19 13.7 71 25.7 ## 20 13.8 64 24.9 ## 21 14.0 78 34.5 ## 22 14.2 80 31.7 ## 23 14.5 74 36.3 ## 24 16.0 72 38.3 ## 25 16.3 77 42.6 ## 26 17.3 81 55.4 ## 27 17.5 82 55.7 ## 28 17.9 80 58.3 ## 29 18.0 80 51.5 ## 30 18.0 80 51.0 ## 31 20.6 87 77.0 So far so good. To produce a basic scatter plot in R is very simple. We use the plot command. In this example, we need to specify which parts of the trees dataset we are going to use. Just as revision, we will try three different ways of doing this - all will produce the same plot, but each one has a subtly different use. In the first example, we select a subscript from the dataframe using square brackets [,1]. Refer back to Getting data into R if you are unsure. This can be a useful way to select data from a larger dataset, if for instance we are dealing with matrices. plot( x = trees[,1], y = trees[,2] ) The second way, we will use the $ operator to select a column from within the dataframe: plot( x = trees$Girth, y = trees$Height ) And finally, we can try the with() function. Using with() dispenses with the need for the $ operator, and allows us to call objects within a dataframe without specifying the name of the dataframe every time. with( trees, plot( x = Girth, y = Height ) ) It doesn’t really matter which method you use in this example, but it is useful to revise different ways of getting at data within a dataframe This plot is not particularly inspiring, so let’s look at some of the ways we can make it nicer. Within the plot command, there are a number of arguments that we can change in order to alter the appearance of the plot, these are here, lifted from the help file for ?plot. You can get a similar list of arguments for any of the other plot functions (or indeed any function) by calling up the help file for that function (just place a “?” in front of the function: e.g. ?boxplot). 7.0.1 Point colour and shape So lets change some general things first. We’ll label the axes (xlab or ylab) and change the shape (pch) and colour (col) of the points. with( trees, plot( x = Girth, y = Height, xlab = &quot;Girth (in)&quot;, ylab = &quot;Height (ft)&quot;, pch = 16, col = &quot;red&quot; ) ) A little bit better… Note that there a wide range of symbol shapes available… …and pretty much any colour you can imagine. Colours can either be specified as a name (e.g. “red”), as a hexadecimal code (e.g. col = &quot;#FF0000&quot;) or in RGB format (e.g. col = rgb(1, 0, 0)). Try http://www.colorpicker.com/ if you get stuck. Note that unless you are going to pay for colour figures in journal plates, or you can be sure that no colour blind people will read your work, it is good practice to use a combination of colours and symbols We can use the package RColorBrewer to make picking complementary colour palettes a little easier. See ?RColorBrewer or http://colorbrewer2.org for more information. There are a number of palettes for different applications. We will just use the first of them - this palette is good for colouring lines and points, but should be avoided for blocks of colour. We can see the various palettes with: display.brewer.pal( n = 9, name = &quot;Set1&quot; ) And create our palette with: pal &lt;- brewer.pal( n = 9, name = &quot;Set1&quot; ) Note that RColorBrewer specifies colours with hexadecimals: pal ## [1] &quot;#E41A1C&quot; &quot;#377EB8&quot; &quot;#4DAF4A&quot; &quot;#984EA3&quot; &quot;#FF7F00&quot; &quot;#FFFF33&quot; &quot;#A65628&quot; ## [8] &quot;#F781BF&quot; &quot;#999999&quot; 7.0.2 Axes and outlines We are also able to customise the axes in any way we want, but it is usually necessary to remove the axes altogether with xaxt=&quot;n&quot; and/or yaxt=&quot;n&quot; and replace them with the axis command. This example also demonstrates the use of the bty argument. with( trees, plot( x = Girth, y = Height, xlab = &quot;Girth (in)&quot;, ylab = &quot;Height (ft)&quot;, pch = 16, col = pal[2], # second colour from the palette we produced. yaxt = &quot;n&quot;, # remove the y axis xaxt = &quot;n&quot;, # remove the y axis cex.lab = 1.2, # scaling factor relating to the size of axis titles. cex = 1.4, # scaling factor for the size of points bty = &quot;l&quot; # this can be either &quot;o&quot;, &quot;l&quot; or &quot;u&quot; ) # and affects the box bordering the plot ) axis( side = 1, # 1=below, 2=left, 3=above and 4=right. at = seq(0,20,4), # a sequence denoting the location of axis tick marks cex.axis = 1.2 # a scaling factor of the default text size ) axis( side = 2, at = seq(50,100,5), las = 2, # Rotate axis labels cex.axis = 1.2 ) 7.0.3 Additional observations If we want to add additional observations to a plot, it is quite simple. We can use the points command, which is specified in a very similar way to the original plot command. In this example, we will use the same trees dataset and plot as the previous example, but we will add a second set of observations which we have simulated using jitter. The jitter command adds a small amount of ‘noise’ to an observation by adding or removing a small amount from it. # Repeat the same code as the last example: with( trees, plot( x = Girth, y = Height, xlab = &quot;Girth (in)&quot;, ylab = &quot;Height (ft)&quot;, pch = 16, col = pal[2], # second colour from the palette we produced. yaxt = &quot;n&quot;, # remove the y axis xaxt = &quot;n&quot;, # remove the y axis cex.lab = 1.2, # scaling factor relating to the size of axis titles. cex = 1.4, # scaling factor for the size of points bty = &quot;l&quot; # this can be either &quot;o&quot;, &quot;l&quot; or &quot;u&quot; ) # and affects the box bordering the plot ) axis( side = 1, # 1=below, 2=left, 3=above and 4=right. at = seq(0,20,4), # a sequence denoting the location of axis tick marks cex.axis = 1.2 # a scaling factor of the default text size ) axis( side = 2, at = seq(50,100,5), las = 2, # Rotate axis labels cex.axis = 1.2 ) # Add an additonal set of points: with( trees, points( x = jitter(Girth, amount=2), # See ?jitter for details y = jitter(Height, amount = 2), pch = 15, col = pal[1], cex = 1.4 ) ) # We also now need to add a legend: legend( &quot;bottomright&quot;, # this can also take the form of x and y coordinates legend = c(&quot;Jittered&quot;,&quot;Original&quot;), # labels for the legend col = pal[1:2], # colour in order of appearance pch = c(15:16), # pch in order of appearance pt.cex = 1.4, # size of legend points bty=&quot;n&quot; # remove the black outline from the legend ) Note that in the above example we would need to adjust the limits of the x and y axes in order to accommodate all of the extra points which we added. This can be done with the arguments xlim=c(1,2) or ylim=c(1,2), substituting the lowest and highest numbers for the 1 and 2. 7.0.4 Log transformations It is sometimes necessary to transform your data when plotting. This is quite easy to achieve in R. In this example, we will import directly from an online text file (also from Crawley’s R book). sapdecay &lt;- read.table( &quot;http://www.bio.ic.ac.uk/research/mjcraw/therbook/data/sapdecay.txt&quot;, header = T ) We’ll call the data to examine it. Note this data is dealt with on p70 of ‘The R Book’. remember that typing the name of the object sapdecay is the ‘short-hand’ equivalent of typing print(sapdecay) - there are certain occasions when it will be necessary to use the full command - more of that later. sapdecay ## x y ## 1 0 1.00000000 ## 2 2 0.96023540 ## 3 4 0.84466377 ## 4 6 0.70693633 ## 5 8 0.70864140 ## 6 10 0.60979536 ## 7 12 0.51325264 ## 8 14 0.47139969 ## 9 16 0.38408127 ## 10 18 0.37227780 ## 11 20 0.33408743 ## 12 22 0.27330733 ## 13 24 0.25162333 ## 14 26 0.22278651 ## 15 28 0.21021653 ## 16 30 0.19059182 ## 17 32 0.16690720 ## 18 34 0.14073164 ## 19 36 0.12028785 ## 20 38 0.11646071 ## 21 40 0.09273687 ## 22 42 0.08397261 ## 23 44 0.08829140 ## 24 46 0.07179059 ## 25 48 0.05932741 ## 26 50 0.06170623 7.0.4 Exercise Now plot the data producing the graph below. Remember to check the arguments listed above if you don’t know how to do something. plot( x = sapdecay$x, y = sapdecay$y, bty = &quot;l&quot;, ylab = &quot;Radioactive decay&quot;, xlab = &quot;Days&quot;, main = &quot;Radioactive Decay Plot&quot;, col = pal[2], pch = 1, cex = 1.4, cex.axis = 1.2, cex.lab = 1.2 ) It is possible for us to fit a non-linear model to this data. We’re not going to cover non-linear modelling in this material, but it is covered elsewhere in the R book. The code below (.70 in the R book) fits an exponential model to this data lines( x = xv, y = exp(-0.055*xv) ) In general however, it is easier if we can linearise our data somehow. For plots, this can be achieved in two ways in R. Either we add the command log=&quot;x&quot; to convert the x-axis to a base 10 logarithmic scale (or you can specify &quot;y&quot; or &quot;xy&quot; for both), or we can convert the data itself before plotting using the log10() command. 7.0.4 Exercise Reproduce the above graph again, but this time try specifying log=&quot;y&quot;.Then try by converting y to a logarithmic scale with log10(y). You should produce the two plots below: Notice that when we log the axes rather than the data, the axis labels remain a lot more comprehensible. We are now able to fit a linear model to this data, which is mathematically simpler than specifying a non-linear model. abline( lm( formula = log10(y)~x, data = sapdecay ) ) 7.0.5 Customising white space So by now, you may be realising that pretty much everything in R plots can be customised. This includes the amount of whitespace you leave around your plots. This can very useful to change when you are creating two plots next to each other. I’m not going to dwell on how to do this, because there are already some excellent guides written on the internet (see: http://research.stowers-institute.org/efg/R/Graphics/Basics/mar-oma/). One of the plots from this page is included below, showing which commands control whitespace around a plot. Maybe take a deep breath first before looking at the code on the website! "],
["histograms-and-box-and-whisker-plots.html", "Chapter 8 Histograms and Box and whisker plots", " Chapter 8 Histograms and Box and whisker plots Histograms and boxplots are two methods of displaying information about the distribution of a dataset. The good news is that most of the commands that we have covered in the previous section on scatterplots and generic, and they can also be used when producing histograms and boxplots. 8.0.1 Histograms We’ve already plotted one histogram in the previous section, so let’s look again at that plot. First, we will look at the data. hist( normal_data ) Simple enough. But if like me, you are a little pedantic about your plots, you may also want to make some changes… hist( normal_data, main = &quot;&quot;, xlab = &quot;Value&quot;, col=&quot;gray80&quot;, cex = 1.4, cex.axis = 1.2, cex.lab = 1.2 ) Bear in mind that we need to make some assumptions when we draw a histogram - i.e. where to choose the break points for the bins (columns). It’s usually fine to leave R to make the decision for us, but we can see the result of making changes to the break points below. You may also at some point wish to compare two histograms by overlaying one over the other. This can be done with a few tweaks, as seen in the example below. Note that we have again had to specify the number of breaks. Hence we have made some assumptions about how to display this data. set.seed(1337) # create two normally distributed vectors of random data data_a &lt;- rnorm( 100, mean = 0, sd = 2 ) data_b &lt;- rnorm( 100, mean = 2, sd = 2 ) # Plot first graph p1&lt;-hist( data_a, ylim = c(0,25), col = rgb(1,0,0,0.5), main = &quot;&quot;, breaks = 10, xlab = &quot;Value&quot;, cex = 1.4, cex.axis = 1.2, cex.lab = 1.2 ) # Note that you must specify an &#39;alpha&#39; of less than 1 (the fourth argument in # the rgb command), otherwise, your two colours will be completely solid. # Plot second graph - note use of &#39;add = TRUE&#39; to overlay onto the first plot p2&lt;-hist( data_b, breaks = 10, add = TRUE, col = rgb(0,0,1,0.5), cex = 1.4, cex.axis = 1.2, cex.lab = 1.2 ) 8.0.2 Box and whisker plots Boxplots similarly display information about the distribution of data, and the have the benefit of not having to make assumptions about bin width. They are not completely free of assumptions however. A basic boxplot is shown below. set.seed(1337) boxplot_data &lt;- rnorm( n = 500, sd = 10, mean = 1 ) boxplot( x = boxplot_data, col = &quot;aliceblue&quot;, cex = 1.4, cex.axis = 1.2, cex.lab = 1.2 ) In this example the thick line at the centre shows the median, the top and bottom of the box shows the upper and lower quartile, whilst the ‘whisker’ show the upper and low adjacent values. These are the highest and lowest values within 1.5 times the interquartile range (upper - lower quartile) of the upper and lower quartile respectively. Any values beyond the adjacent values are considered ‘outliers’ and represented by points. Note that this is not the only way of representing data in box and whisker plots. The other possibilities are listed here: http://en.wikipedia.org/wiki/Box_plot. For this reason, you should always mention what your boxplot is actually showing in the caption. 8.0.2.1 Multiple box plots One of the great strengths of the boxplot, is that it allows you to plot several different data sets side by side, in a much more simple and easily comparable manner than with histograms. 8.0.2.1 Exercise In the next example we will use a real dataset which you are required to download from the internet and load into R using the methods we have learnt so far. The data are available here: https://db.tt/JEoe3mQZ Save this file to your desktop and import it to R, so that R recognises the column headings. Call the new variable car_prices. This data compares the asking two prices of two cars: one diesel, and one petrol, from 216 car adverts. In the following example we will produce boxplots which compare the asking prices. We need to use the split() command for this. The split() command literally splits a dataset according to a particular categorical variable. # Check the data str( car_prices ) ## &#39;data.frame&#39;: 216 obs. of 5 variables: ## $ year : int 2005 2005 2005 2005 2005 2005 2005 2005 2005 2005 ... ## $ miles: int 91000 113452 114000 157000 117000 98000 91000 88000 72150 110000 ... ## $ price: int 1795 1900 1945 1989 2000 2195 2250 2295 2350 2350 ... ## $ type : Factor w/ 2 levels &quot;private&quot;,&quot;trade&quot;: 2 1 2 2 2 1 1 2 2 2 ... ## $ fuel : Factor w/ 2 levels &quot;diesel&quot;,&quot;petrol&quot;: 2 2 2 2 2 2 2 2 2 2 ... # Split it according to fuel type - note the $ operator - this is required in this case split( car_prices$price, car_prices$fuel ) ## $diesel ## [1] 2590 2995 3485 3295 3295 2545 2871 2951 2195 2690 3250 1795 1495 2495 ## [15] 1995 2495 2295 1789 1995 1795 2395 1895 1250 1695 2495 1800 1999 2295 ## [29] 1499 1550 2489 2490 2000 2475 1525 2495 1290 1795 1880 1990 1195 1390 ## [43] 1750 1787 1770 2500 1600 995 1495 2295 1675 1200 2000 1699 1595 1475 ## [57] 999 1199 1650 1290 1200 995 995 ## ## $petrol ## [1] 1795 1900 1945 1989 2000 2195 2250 2295 2350 2350 2350 2395 2400 2450 ## [15] 2475 2490 2490 2490 2490 2495 2495 2495 2495 2495 2595 2595 2600 2625 ## [29] 2650 2695 2695 2750 2775 2790 2795 2795 2795 2795 2795 2795 2795 2803 ## [43] 2850 2875 2890 2895 2895 2895 2990 2990 2990 2990 2990 2991 2991 2991 ## [57] 2994 2995 2995 2995 2995 2995 2995 2995 2995 2995 2995 2995 2995 2999 ## [71] 3000 3000 3000 3000 3000 3000 3000 3175 3195 3195 3195 3200 3281 3290 ## [85] 3295 3295 3295 3295 3295 3295 3295 3295 3295 3295 3299 3400 3450 3482 ## [99] 3494 3495 3495 3495 3495 3495 3495 3499 3499 3499 3500 3500 3690 3694 ## [113] 3695 3695 3695 3695 3695 3695 3695 3699 3795 3795 3795 3795 3795 3795 ## [127] 3799 3888 3890 3895 3900 3970 3985 3990 3990 3991 3995 3995 3995 3995 ## [141] 3995 3995 3995 3995 4000 4000 4000 4190 4288 4295 4295 4295 4390 # This can simply be wrapped by a call to the boxplot() function boxplot( split( car_prices$price, car_prices$fuel ), col = c(&quot;#66C2A5&quot;,&quot;#FC8D62&quot;) ) We can make additional splits to this dataset if we like, by using a list of factors to split the data by. boxplot( split( car_prices$price, list( car_prices$fuel, car_prices$type ) ), col = c(&quot;#66C2A5&quot;,&quot;#FC8D62&quot;), ylab=bquote(Asking~Price~(&quot;£&quot;)) ) # Using bquote() is required here to display the £ sign correctly 8.0.2.1 Exercise Using the methods above, produce a boxplot of the car_prices data, splitting teh data by seller type "],
["multiple-plots.html", "Chapter 9 Multiple plots", " Chapter 9 Multiple plots You may have noticed in one of the previous examples, that two plots were produced one on top of the other. This is a pretty easy thing to accomplish. All we need to do is split the plotting area with the par(mfrow=c(x,y)) command. As with subscripts, with this command x codes for the number of rows, and y represents the number of columns. Check ?par for more information. par(mfrow = c(2,2)) with( sapdecay, plot( x = x, y = y, xlab = &quot;Time (hours)&quot;, ylab = &quot;Decay rate&quot;, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 2, main = &quot;Line&quot; ) ) with( sapdecay, plot( x = x, y = y, xlab = &quot;Time (hours)&quot;, ylab = &quot;Decay rate&quot;, type = &quot;o&quot;, col = &quot;green&quot;, lwd = 1, main = &quot;Overplot&quot; ) ) with( sapdecay, plot( x = x, y = y, xlab = &quot;Time (hours)&quot;, ylab = &quot;Decay rate&quot;, type = &quot;h&quot;, col = &quot;blue&quot;, lwd = 2, main = &quot;Histogram&quot; ) ) with( sapdecay, plot( x = x, y = y, xlab = &quot;Time (hours)&quot;, ylab = &quot;Decay rate&quot;, type = &quot;s&quot;, col = &quot;hotpink&quot;, lwd = 2, main = &quot;Step&quot; ) ) # It&#39;s important that we reset the mfrow parameter at the end of plotting, # otherwise all subsequent plots will appear on this four by four grid, which # may not be what we want. par(mfrow = c(1,1)) Using this method, it’s also perfectly possible to combine plots of two different types, and plot them next to each other. Let’s imagine that we want to test whether a variable is normally distributed - there are two very simple graphical commands built into R that make this easier: qqnorm and qqline. These commands produce quantile-quantile plots for the normal distribution. Essentially if the data are normally distributed, they will conform to the straight line[1]. First we will create a vector of random numbers drawn from a normal distribution - so we already know that they are normal! normal_data &lt;- rnorm( 100, mean=0, sd=1 ) normal_data ## [1] 0.19249191 -1.44670181 -0.32318053 1.62229612 -0.68902412 ## [6] 2.04212222 0.94377911 2.08192688 1.91711728 -0.41481224 ## [11] 1.03285350 -1.67856959 0.15754969 1.48913612 -0.07578956 ## [16] 1.27178094 0.64167341 0.80076125 1.86265923 -0.54535603 ## [21] 0.61927781 0.12264043 -0.79098417 -0.49977167 -1.63515201 ## [26] 1.78456732 0.29887827 0.75250489 -1.07460214 0.06427374 ## [31] 1.26264948 1.09994930 -1.12355513 3.44607885 -0.71972217 ## [36] -0.32685410 -0.52977397 0.52415274 -1.07960965 -0.05511102 ## [41] 2.19868418 -1.77390933 0.06503223 0.65497038 -0.71286911 ## [46] 1.02056754 0.63161472 0.44743335 0.46653706 -0.69826061 ## [51] -0.03645455 1.11796617 -0.70008253 -1.12404818 -0.61306728 ## [56] 1.01244271 -2.34387016 0.59026309 0.31913434 0.70160645 ## [61] -1.37745713 0.31264588 1.12084758 0.47183089 1.12768532 ## [66] 0.67772314 1.51023992 2.06103435 -0.65031591 -1.32423767 ## [71] 0.65947131 -0.22142515 -0.96215911 0.18746019 0.01224463 ## [76] 0.71228374 -0.75372581 0.03818993 1.17842106 -0.15320385 ## [81] -0.16169753 1.46026211 2.00945844 -0.07793822 1.35434208 ## [86] -1.02718379 -1.04117532 -0.87062302 0.85313022 -0.62276019 ## [91] 1.21570987 -1.62140875 -0.06857533 -0.06298292 1.07570771 ## [96] 1.12910075 0.45014673 0.05058644 -0.12433022 0.91201146 And now…some plots. First, two plots side by side. par( mfrow=c(1,2) ) # Remember that the first number is the number of rows, the latter is the number # of columns. So here, we have specified one row, two columns... # Now the plots: hist(normal_data) qqnorm(normal_data) qqline(normal_data) So things should look pretty normal. In this example we have not specified a ‘seed’ (see ?set.seed for more info). So every time that you run the code, you will get a different set of randomly generated numbers drawn from a normal distribution. All well and good, but what about one above the other? Just changed the 1 and 2 around in the par(mfrow=c(x,y)) command. par(mfrow=c(2,1)) # Remember that the first number is the number of rows, the latter is the number # of columns. So here, we have specified one row, two columns... # Now the plots: hist(normal_data) qqnorm(normal_data) qqline(normal_data) 9 Exercise Using what you have learnt in the previous sections, and the data from the car_prices, have a go at reproducing the plots you see below. Most of what you need to know has been covered, though you will need to consult the help files for certain commands. car_prices &lt;- read.table( &quot;discount.csv&quot;, header = T, sep = &quot;,&quot; ) par( mar = c( 4.1, 4.5, 0.5, 0.5), mgp = c( 2.1, 0.6, 0), mfrow = c(2,2), cex = 1.4, cex.lab = 1.2, cex.axis = 1.2, lend=&quot;square&quot; ) diesel &lt;- subset(car_prices,fuel == &quot;diesel&quot;) petrol &lt;- subset(car_prices,fuel == &quot;petrol&quot;) p1&lt;-hist( diesel$price, ylim = c(0,60), col = rgb(1,0,0,0.5), # Note that the colours used must be those that allow transparency main = &quot;&quot;, breaks = 8, xlab = bquote(Asking~price~(10^3~&quot;£&quot;)), xlim = c(5,5500), yaxt = &quot;n&quot;, xaxt = &quot;n&quot; ) # plot second graph - note use of &#39;add = TRUE&#39; to overlay onto the first plot p2&lt;-hist( petrol$price, breaks = 8, add = TRUE, col = rgb(0,0,1,0.5) ) axis( side = 2, at = seq(0,60,10), las = 2 ) axis( side = 1, labels = seq(0,5,1), at = seq(0,5000,1000), las = 1 ) legend( &quot;topleft&quot;, legend = c(&quot;Petrol&quot;,&quot;Diesel&quot;), fill = c(rgb(0,0,1,0.5),rgb(1,0,0,0.5)), bty = &quot;n&quot; ) boxplot( split( car_prices$price, car_prices$fuel ), col = c(rgb(1,0,0,0.5),rgb(0,0,1,0.5)), ylab = bquote(Asking~price~(10^3~&quot;£&quot;)), yaxt = &quot;n&quot; ) axis( side = 2, labels = seq(0,10,1), at = seq(0,10000,1000), las = 2 ) with( petrol, plot( miles, price, col = rgb(0,0,1,0.5), ylim = c(500,5000), xlim=c(20000,180000), xlab = bquote(Mileage~(10^3~miles)), ylab = bquote(Asking~price~(10^3~&quot;£&quot;)), yaxt = &quot;n&quot;, xaxt = &quot;n&quot;, bty = &quot;l&quot;, pch = 16, cex = 1.2 ) ) with( diesel, points( miles, price, col = rgb(1,0,0,0.5), pch = 17, cex = 1.2 ) ) axis( side = 2, labels = seq(0,10,1), at = seq(0,10000,1000), las = 2 ) axis( side = 1, at = seq(0,200000,20000), labels = seq(0,200,20) ) legend( &quot;topright&quot;, col = c(rgb(0,0,1,0.5),rgb(1,0,0,0.5)), legend = c(&quot;Petrol&quot;,&quot;Diesel&quot;), pch = c(16:17), bty = &quot;n&quot;, cex = 1.2 ) ############### qqnorm( car_prices$miles, main = &quot;QQ plot of mileage&quot; ) qqline( car_prices$miles, col = &quot;red&quot;, lty = 2 ) # boxplot( # split( # car_prices$miles/car_prices$price, # car_prices$fuel # ), # col = c(rgb(1,0,0,0.5),rgb(0,0,1,0.5)), # ylab = bquote(Miles~&quot;£&quot;^-1), # yaxt = &quot;n&quot; # ) # axis( # side = 2, # at = seq(0,200,40), # las = 2 # ) par(mfrow=c(1,1)) &lt; id=“footnote-1”&gt;[1] I’m not going to dwell on the reasons why this is so - we’re more interested in the plotting graphs than the statistics behind it in this sections, but if you don’t understand what is going on here, you should look it up! http://en.wikipedia.org/wiki/Q-Q_plot. "],
["t-tests.html", "Chapter 10 T-tests", " Chapter 10 T-tests As mentioned at the beginning of this course, I am not going to discuss which tests you should use, or why you should use them. I am simply going to show you HOW to use them in R When running t-tests, there is a simple, built in function we can use. See ?t.test for more information. In this example we will use Crawley’s t.test data from .296 of the R book. t.test.data &lt;- read.table( &quot;http://www.bio.ic.ac.uk/research/mjcraw/therbook/data/t.test.data.txt&quot;, header = T ) t.test.data ## gardenA gardenB ## 1 3 5 ## 2 4 5 ## 3 4 6 ## 4 3 7 ## 5 2 4 ## 6 3 4 ## 7 1 3 ## 8 3 5 ## 9 5 6 ## 10 2 5 Remember that we must always satisfy ourselves that the data are normally distributed before completing a t-test, if not, the assumptions of these tests do not hold. You should consider the other assumptions of a t-test too, before you run the test. gardenA &lt;- t.test.data$gardenA gardenB &lt;- t.test.data$gardenB par(mfrow=c(1,2)) qqnorm(gardenA) qqline(gardenA) qqnorm(gardenB) qqline(gardenB) par(mfrow=c(1,1)) OK great…this data looks pretty normal. Let’s complete the t.test() In this example we have assumed that the gardens are paired plots, and that we are interested in a two sided test. If you are not sure what is meant by these terms, you should read up on it before attempting to complete the test: Wikipedia is a surprisingly good resource for statistical information. t.test( x = gardenA, y = gardenB, alternative = &quot;two.sided&quot;, paired = TRUE ) ## ## Paired t-test ## ## data: gardenA and gardenB ## t = -6.7082, df = 9, p-value = 8.771e-05 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.674445 -1.325555 ## sample estimates: ## mean of the differences ## -2 The output gives us the test statistic, the degrees of freedom, and the -value - simple. Note that if you want to automate t.test, or another test, you can extract the results from the test object like so: example_test &lt;-t.test( x = gardenA, y = gardenB, alternative = &quot;two.sided&quot;, paired = TRUE ) example_test$statistic ## t ## -6.708204 example_test$parameter ## df ## 9 example_test$.value ## NULL So yes….it appears that our two samples are significantly different, because the test statistic is greater than our critical t value. We can can calculate the critical t value to check this: qt( 0.975, # 0.975 because it is a two tailed test and 2*(1-0.975) = 0.05! df = 9 ) ## [1] 2.262157 # We ignore signs in a two-sided t-test, hence if the absolute value of the test # statistic is greater than the critical value, we reject the null hypothesis: abs(example_test$statistic) &gt; qt(0.975,9) ## t ## TRUE Easy! "],
["linear-regression.html", "Chapter 11 Linear regression 11.1 Transformation", " Chapter 11 Linear regression Linear regression can be completed in a similarly uncomplicated way in R. In this example, we will revisit the trees dataset we used earlier trees ## Girth Height Volume ## 1 8.3 70 10.3 ## 2 8.6 65 10.3 ## 3 8.8 63 10.2 ## 4 10.5 72 16.4 ## 5 10.7 81 18.8 ## 6 10.8 83 19.7 ## 7 11.0 66 15.6 ## 8 11.0 75 18.2 ## 9 11.1 80 22.6 ## 10 11.2 75 19.9 ## 11 11.3 79 24.2 ## 12 11.4 76 21.0 ## 13 11.4 76 21.4 ## 14 11.7 69 21.3 ## 15 12.0 75 19.1 ## 16 12.9 74 22.2 ## 17 12.9 85 33.8 ## 18 13.3 86 27.4 ## 19 13.7 71 25.7 ## 20 13.8 64 24.9 ## 21 14.0 78 34.5 ## 22 14.2 80 31.7 ## 23 14.5 74 36.3 ## 24 16.0 72 38.3 ## 25 16.3 77 42.6 ## 26 17.3 81 55.4 ## 27 17.5 82 55.7 ## 28 17.9 80 58.3 ## 29 18.0 80 51.5 ## 30 18.0 80 51.0 ## 31 20.6 87 77.0 Now let us assume that there is likely to be a correlation between Girth and Volume, and we want to examine this with a linear model. We start by plotting the data with( trees, plot( x = Girth, y = Volume ) ) So it looks like there is a positive relationship…let’s explore this with linear regression. We specify a model formula of Volume ~ Girth, which means Volume is dependent on Girth. model &lt;- lm( formula = Volume ~ Girth, data = trees ) We must call the results of the test with summary. summary(model) ## ## Call: ## lm(formula = Volume ~ Girth, data = trees) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.065 -3.107 0.152 3.495 9.587 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -36.9435 3.3651 -10.98 7.62e-12 *** ## Girth 5.0659 0.2474 20.48 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.252 on 29 degrees of freedom ## Multiple R-squared: 0.9353, Adjusted R-squared: 0.9331 ## F-statistic: 419.4 on 1 and 29 DF, p-value: &lt; 2.2e-16 So we get quite a lot of output… First we are reminded of the model we called: model$call ## lm(formula = Volume ~ Girth, data = trees) Then we get some summary information from the residuals - the minimum, maximum, median, and the 1st and 3rd quartiles. Remember that our residuals should be normally distributed in a regression model, so we can get an initial idea of whether this is so from this summary: summary(model$residuals) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -8.065 -3.107 0.152 0.000 3.495 9.587 Then we get the juicy stuff… (summary(model))$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -36.943459 3.365145 -10.97827 7.621449e-12 ## Girth 5.065856 0.247377 20.47829 8.644334e-19 First we get the model coefficients. Note that the name of the response variable (Volume) has been replaced with (Intercept), and the first value immediately to the right of this is the intercept of our regression line. The number beneath this is the slope of our regression line - hence these two can be considered as α and β in the equation y = &amp;alpha; + &amp;beta;x Hence we can use them to plot the regression line represented by the model with: plot( x = trees$Girth, y = trees$Volume ) abline( a = coef(model[1]), b = coef(model[2]) ) # Or more simply: abline(model) We also get the results from t-tests on the two variables: (summary(model))$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -36.943459 3.365145 -10.97827 7.621449e-12 ## Girth 5.065856 0.247377 20.47829 8.644334e-19 The number of interest to us is &lt;0.00276**, which tells us that there is a significant correlation (which is positive because the t value 3.272 is also positive) between Volume and Girth Other pertinent information is the r-square (R2) and adjusted-r-squared values (R2). If you don’t know what these are you should look them up: http://en.wikipedia.org/wiki/R-squared. If we want to include this information on the graph, we can: plot( x = trees$Girth, y = trees$Volume, pch = 16, col = &quot;hotpink&quot;, cex = 1.4 ) abline(model) formula_text &lt;- paste( &quot;y=&quot;, round(coef(model)[1],2), &quot;+&quot;, round(coef(model)[2],2), &quot;x, &quot;, sep=&quot;&quot; ) rsquared_text = paste( &quot;=&quot;, round( (summary(model))$r.squared ,2 ) ) text( substitute( paste(ft, R^2, rt), list(ft=formula_text,rt = rsquared_text) ), x = 12, y = 75 ) All good - but we do need to check the model diagnostic plots to ensure that we have met the assumptions of a linear model. par(mfrow=c(4,1)) plot(model) par(mfrow=c(1,1)) As I keep saying, this is not a statistics course. If you don’t know what you are looking at here, You should find. These plots are discussed in the R book on p.357, but in general terms the first and third plot should should look like a sky at night, without any particular patternation - and in particular the data should not be clustered in a wedge shape. The second plot should generally follow the straight line indicated - this is the same as the qqnorm plot discussed elsewhere in the course. 11.1 Transformation The astute amongst you may have noticed that we could improve the fit of the model by transforming the data - probably with a log transformation. Let’s try this now: model1 &lt;- lm( formula = log10(Volume) ~ log10(Girth), data = trees ) summary(model1) ## ## Call: ## lm(formula = log10(Volume) ~ log10(Girth), data = trees) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.089464 -0.029837 0.000439 0.031523 0.107689 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.02204 0.10018 -10.20 4.18e-11 *** ## log10(Girth) 2.19997 0.08983 24.49 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.04993 on 29 degrees of freedom ## Multiple R-squared: 0.9539, Adjusted R-squared: 0.9523 ## F-statistic: 599.7 on 1 and 29 DF, p-value: &lt; 2.2e-16 Yes, the R-squared is slightly better than with the transformed model. Now let’s reproduce the plot, this time with log10 transformed axes: par(mfrow=c(2,1)) plot( x = trees$Girth, y = trees$Volume, pch = 16, col = &quot;hotpink&quot;, cex = 1.4, main = &quot;Untransformed&quot; ) abline(model) plot( x = trees$Girth, y = trees$Volume, pch = 16, col = &quot;hotpink&quot;, cex = 1.4, log = &quot;xy&quot;, main = &quot;Transformed&quot; ) abline(model1) par(mfrow=c(1,1)) A nice touch when plotting data on transformed axes, is to produce a plot of the original data within the first plot with the model line plotted untransformed. # Create intial plot plot( x = trees$Girth, y = trees$Volume, pch = 16, col = &quot;hotpink&quot;, cex = 1.4, log = &quot;xy&quot;, main = &quot;Volume ~ Girth &quot;, bty = &quot;l&quot;, xlab = &quot;Girth (in)&quot;, ylab = bquote(Volume~(ft^3)), yaxt = &quot;n&quot; ) axis( side = 2, las = 2 ) # Plot regression line abline( model1, lty = 2, lwd = 2, col = rgb(0,0,1,0.5) ) # Set up graphical parameters for sub plot see ?par par( fig = c(0.6,1,0.075,0.6), new = T, bty = &quot;o&quot;, cex.axis = 0.8, cex.lab = 0.8, mgp = c( 1.95, 0.3, 0), tck = -0.02 ) # Plot sub plot # Note that x and y axes have been suppressed, as have annotations plot( x = trees$Girth, y = trees$Volume, pch = 16, col = &quot;hotpink&quot;, ann = FALSE, xlim = c(5,20), ylim = c(5,70), xaxt = &quot;n&quot;, yaxt = &quot;n&quot; ) # Use predict to calculate the untransformed model. Note the untf=T lines( 10 ^ predict( model1, list(Girth = 1:50), untf = T ), lty = 1, lwd = 2, col = rgb(0,0,1,0.5) ) # Add x-axis axis( side=1, at = seq(0,20,5), lwd = 0.5 ) # Add y-axis axis( side = 2, at = seq(0,100,20), las = 2, lwd = 0.5 ) # Reset the plotting parameters par( fig=c(0,1,0,1), new = F ) Finally, we should check the model assumptions again… par(mfrow=c(4,1)) plot(model1) par(mfrow=c(1,1)) The diagnostic plots seem to be a little better for the transformed data. Hence it seems like a justified choice to transform the data. "],
["anova.html", "Chapter 12 ANOVA 12.1 One-way ANOVA 12.2 Two-way ANOVA", " Chapter 12 ANOVA 12.1 One-way ANOVA Analysis of variance is simple enough in R, using the aov() command. We will start with a simple One-Way ANOVA. We’ll use data on the effect of two paint application methods (applic) and three primers (primer) on the quality of paint adherence (adhf). You will need to download this data from https://raw.githubusercontent.com/ivyleavedtoadflax/R_notes/master/paint.csv, and import the data into R using one of the methods we have discussed previously. Call the dataframe paint. paint ## adhf primer applic ## 1 4.0 1 Dipped ## 2 4.5 1 Dipped ## 3 4.3 1 Dipped ## 4 5.6 2 Dipped ## 5 4.9 2 Dipped ## 6 5.4 2 Dipped ## 7 3.8 3 Dipped ## 8 3.7 3 Dipped ## 9 4.0 3 Dipped ## 10 5.4 1 Sprayed ## 11 4.9 1 Sprayed ## 12 5.6 1 Sprayed ## 13 5.8 2 Sprayed ## 14 6.1 2 Sprayed ## 15 6.3 2 Sprayed ## 16 5.5 3 Sprayed ## 17 5.0 3 Sprayed ## 18 5.0 3 Sprayed First we consider only the effect of primer - a one way ANOVA. model &lt;- aov( adhf ~ primer, data = paint ) We need to call the results of this analysis with summary. summary(model) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## primer 1 0.241 0.2408 0.368 0.553 ## Residuals 16 10.477 0.6548 We get the usual ANOVA table that we would expect from this kind of analysis. Importantly, we see that the primer type does not appear to have a significant influence on the adherence of the paint (=0.55). But wait! We didn’t specify that primer is meant to be a factor. Since it is numeric, R has no way of implicitly knowing this, so is currently treating primer as a continuous variable, which it definitely is not! Let’s re-run the analysis correctly identifying primer as a categorical variable. paint$primer &lt;- factor(paint$primer) str(paint) ## &#39;data.frame&#39;: 18 obs. of 3 variables: ## $ adhf : num 4 4.5 4.3 5.6 4.9 5.4 3.8 3.7 4 5.4 ... ## $ primer: Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 2 2 2 3 3 3 1 ... ## $ applic: Factor w/ 2 levels &quot;Dipped&quot;,&quot;Sprayed&quot;: 1 1 1 1 1 1 1 1 1 2 ... model &lt;- aov( adhf ~ primer, data = paint ) summary(model) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## primer 2 4.581 2.2906 5.599 0.0153 * ## Residuals 15 6.137 0.4091 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This time, we see that primer type does have a significant effect. Let’s plot the data: boxplot( split( paint$adhf, paint$primer ) ) So it looks like primer 2 is the most effective, but we still don’t know if there are significant differences between primer 1 and 2, and 1 and 3, although we can guess there is a significant difference between 1 and 3. We can use model.tables() to get a list of the effects: model.tables( x = model, type=&quot;mean&quot;, se = TRUE ) ## Tables of means ## Grand mean ## ## 4.988889 ## ## primer ## primer ## 1 2 3 ## 4.783 5.683 4.500 ## ## Standard errors for differences of means ## primer ## 0.3693 ## replic. 6 This gives us the treatment means, and the standard error of the differences. Note that a more versatile way of calculating data for groups is the melt and cast methods that we have used earlier. 12.1 Exercise Get the median, mean, standard deviation, standard error, upper and lower 95% confidence intervals for the three primers in the paint data se &lt;- function(x) { sd(x)/sqrt(length(x)) } uci95 &lt;- function(x) { mean(x) + qt(0.975,df = length(x)-1) * sd(x) / sqrt(length(x)) } lci95 &lt;- function(x) { mean(x) - qt(0.975,df = length(x)-1) * sd(x) / sqrt(length(x)) } 12.1.1 Multiple comparisons If we really want to know whether there are significant differences between the means, we need to do some sort of multiple comparison test. Be aware that there are dozens of possible multiple comparison tests, and there is some controversy about their use. In particular, you should be aware of controlling the family-wise error rate, which can be inflated in uncontrolled ‘least significant difference’ (LSD) tests. See http://en.wikipedia.org/wiki/Multiple_comparisons and http://en.wikipedia.org/wiki/Familywise_error_rate for more information. There is also a discussion of the problem on p.482 of the R book. There are built in functions to do this analysis, but we will use the package agricolae which has greater functionality. For this example we will use Tukey’s Honest Significant Difference test (HSD), which provides a reasonably conservative test. library(agricolae) # Note that here we have to specify the response (y) and the treatment (trt) of # interest, in adittion to the mean residual mean squares and residual degree of # freedom. These are taken from the summary(model) table. # # HSD_primer &lt;- HSD.test( y = paint$adhf, trt = paint$primer, MSerror = 0.4091, DFerror = 15, alpha = 0.05 ) # Note that it is possible to automate the extraction of these values from the # model object. And this is worth doing if you are running a lot of multiple # comparison tests. # # # Here is some code I have written to do just that. The if statements deal with # the cases in which you have a nested experimental structure. # # ms_w &lt;- function(x) { if (&quot;Within&quot; %in% names(x)) { y &lt;- summary(x$Within)[[1]][[3]] tail(y,1) } else { y &lt;- summary(x)[[1]][[3]] tail(y,1) } } df_w &lt;- function(x) { if (&quot;Within&quot; %in% names(x)) { x$Within$df.residual } else { x$df.residual } } # # Check these against the output from the model: # ms_w(model) ## [1] 0.4091111 df_w(model) ## [1] 15 # # And the test again with the automated functions # HSD_primer &lt;- HSD.test( y = paint$adhf, trt = paint$primer, MSerror = ms_w(model), DFerror = df_w(model), alpha = 0.05 ) HSD_primer ## $statistics ## Mean CV MSerror HSD ## 4.988889 12.82085 0.4091111 0.9592031 ## ## $parameters ## Df ntr StudentizedRange alpha test name.t ## 15 3 3.673378 0.05 Tukey paint$primer ## ## $means ## paint$adhf std r Min Max ## 1 4.783333 0.6306082 6 4.0 5.6 ## 2 5.683333 0.5036533 6 4.9 6.3 ## 3 4.500000 0.7589466 6 3.7 5.5 ## ## $comparison ## NULL ## ## $groups ## trt means M ## 1 2 5.683333 a ## 2 1 4.783333 ab ## 3 3 4.500000 b Amongst all the output we get, is a table of groups: HSD_primer$groups ## trt means M ## 1 2 5.683333 a ## 2 1 4.783333 ab ## 3 3 4.500000 b Here, means with the same letter indicate no significant difference. Hence we see that primer 2 is significantly different from primer 3, but there is no difference between primer 1 and 2, or primer 2 and 3. Note that we used alpha = 0.05, but you can use a more stringent alpha if necessary. We can display these differences using error bars and letters to signify significant differences in the plot below. The function se_lines() can quite easily be adapted to your own plots. library(reshape) ## ## Attaching package: &#39;reshape&#39; ## The following objects are masked from &#39;package:plyr&#39;: ## ## rename, round_any paint_m &lt;- melt( paint, id = 2:3 ) paint_c &lt;- cast( paint_m, primer ~ variable, c(mean,se,lci95,uci95) ) paint_plot &lt;- barplot( paint_c$adhf_mean, ylab = &quot;Adhesion factor&quot;, xlab = &quot;Primer&quot;, ylim = c(0,7), space = 0.1, names = paint_c$primer ) # # # # Specify function to take four arguments: # # x is the dataframe from which the summary data comes, in our case, a cast # object. This object must contain a mean and se column # # y is the name of the plot - we need to give the plot an object name due to # vagaries of the barplot function - by naming it as an object, we can place # labels and error bars more precisely. # # Hline is the length of horizontal lines used in error bars. It is also used to # specify the position of the significance letter. MCT is the name of the # # Multiple comparison test object output from agricolae - this will be an # HSD.test or LSD.test object. # # # se_lines &lt;- function(x,y,Hline,MCT) { # # # Run a loop for the same number of times as we have levels of treatment # factors # # for (i in 1:length(x[,1])) { # # # Find the mean and se columns using grep # # x_mean &lt;- x[,grep(&quot;mean&quot;,names(x))] x_se &lt;- x[,grep(&quot;se&quot;,names(x))] # # # Create error bars # # lines( c(y[i],y[i]), c(x_mean[i]+(x_se[i]),x_mean[i]-(x_se[i])) ) lines( c(y[i]-Hline,y[i]+Hline), c(x_mean[i]+(x_se[i]),x_mean[i]+(x_se[i])) ) lines( c(y[i]-Hline,y[i]+Hline), c(x_mean[i]-(x_se[i]),x_mean[i]-(x_se[i])) ) # # # Add significance letters above the error bars. # # Get the correct order for the significance labels from the agricolae test # object. This step is required, because the output from agricolae test # objects are ordered by effect size, not by the initial order of factors # specified in the input dataframe. # # # sig_labels &lt;- sapply(x[,1], function(z) { MCT$groups$M[grep(z,MCT$groups$trt)] } ) text( y = x_mean[i] + x_se[i] + 5 * Hline, x = y[i], labels = sig_labels[i], cex = 1 ) } } # # # Run the final code: # # se_lines( paint_c, paint_plot, 0.1, HSD_primer ) 12.2 Two-way ANOVA OK so now we will include the effect of application method into our model, creating a Two-way ANOVA. model1 &lt;- aov( formula = adhf ~ primer * applic, data = paint ) Note that we used the formula adhf ~ primer * applic in order to look at all the interactions between the two factors. If we didn’t want to look at the interactions we would use + instead of * - but you need to have a good reason to do this. summary(model1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## primer 2 4.581 2.291 27.858 3.10e-05 *** ## applic 1 4.909 4.909 59.703 5.36e-06 *** ## primer:applic 2 0.241 0.121 1.466 0.269 ## Residuals 12 0.987 0.082 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 So it looks like the primer and applic factors both have a significant effect on adhf, but there is no significant interaction between the two. If you follow the model-simplification method, you might now want to remove this unimportant interaction, leaving you with just the significant interactions: model2 &lt;- update(model1,~.-primer:applic) summary(model2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## primer 2 4.581 2.291 26.12 1.88e-05 *** ## applic 1 4.909 4.909 55.98 2.96e-06 *** ## Residuals 14 1.228 0.088 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 More on this can be found in Crawley. But for now, we will not remove the non-significant terms. We must of course check for the assumptions of a linear model with ANOVA, as with regression. For brevity, we did not do this in the previous example - but you would need to in your analysis. par(mfrow=c(4,1)) plot(model1) par(mfrow=c(1,1)) Additional diagnostic plots can be produced with: par(mfrow=c(4,1)) qqnorm(resid(model1)) qqline(resid(model1)) hist(resid(model1)) plot(density(resid(model1))) plot(fitted(model1),resid(model1)) par(mfrow=c(1,1)) I think we can just about get away with that, although there is some suggestion of non-normality in the QQ plot. Transformation may improve that… Now the multiple comparison test. Again we will use Tukey’s HSD test. We found no interactions between primer and application method. Note that we must re-run our test of primer, because the model has changed, and with it the residual mean squares and the degrees of freedom. HSD_primer &lt;- HSD.test( y = paint$adhf, trt = paint$primer, MSerror = ms_w(model1), DFerror = df_w(model1), alpha = 0.05 ) HSD_primer ## $statistics ## Mean CV MSerror HSD ## 4.988889 5.747656 0.08222222 0.4416697 ## ## $parameters ## Df ntr StudentizedRange alpha test name.t ## 12 3 3.772929 0.05 Tukey paint$primer ## ## $means ## paint$adhf std r Min Max ## 1 4.783333 0.6306082 6 4.0 5.6 ## 2 5.683333 0.5036533 6 4.9 6.3 ## 3 4.500000 0.7589466 6 3.7 5.5 ## ## $comparison ## NULL ## ## $groups ## trt means M ## 1 2 5.683333 a ## 2 1 4.783333 b ## 3 3 4.500000 b HSD_applic &lt;- HSD.test( y = paint$adhf, trt = paint$applic, MSerror = ms_w(model1), DFerror = df_w(model1), alpha = 0.05 ) HSD_applic ## $statistics ## Mean CV MSerror HSD ## 4.988889 5.747656 0.08222222 0.2945156 ## ## $parameters ## Df ntr StudentizedRange alpha test name.t ## 12 2 3.081307 0.05 Tukey paint$applic ## ## $means ## paint$adhf std r Min Max ## Dipped 4.466667 0.6928203 9 3.7 5.6 ## Sprayed 5.511111 0.4960959 9 4.9 6.3 ## ## $comparison ## NULL ## ## $groups ## trt means M ## 1 Sprayed 5.511111 a ## 2 Dipped 4.466667 b So we find that things change for primer under the new model, and there are significant differences between primer 2 and primers 1 and 3: HSD_primer$groups ## trt means M ## 1 2 5.683333 a ## 2 1 4.783333 b ## 3 3 4.500000 b For application method, we see that spray application is more effective than dipping. HSD_applic$groups ## trt means M ## 1 Sprayed 5.511111 a ## 2 Dipped 4.466667 b Let’s plot these together par(mfrow=c(2,1)) paint_plot &lt;- barplot( paint_c$adhf_mean, ylab = &quot;Adhesion factor&quot;, xlab = &quot;Primer&quot;, ylim = c(0,7), space = 0.1, names = paint_c$primer ) se_lines( paint_c, paint_plot, 0.1, HSD_primer ) paint_c2 &lt;- cast( paint_m, applic ~ variable, c(mean,se) ) paint_plot &lt;- barplot( paint_c2$adhf_mean, ylab = &quot;Adhesion factor&quot;, xlab = &quot;Application method&quot;, ylim = c(0,7), space = 0.1, names = paint_c2$applic ) se_lines( paint_c2, paint_plot, 0.1, HSD_applic ) par(mfrow=c(1,1)) "]
]
